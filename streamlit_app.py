import streamlit as st
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
from data_files.data_lr_woe import data as data1
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import seaborn as sns


st.set_page_config(page_title="Main page", page_icon="")

st.title("Metody Scoringowe i Techniki klasyfikacji danych")

st.divider()

ms, tkd = st.tabs(['Projekt MS', 'Techniki klasyfikacji danych'])

with ms: 
    # Zaadowanie danych
    @st.cache_data
    def load_data(file):
        return pd.read_excel(file)

    data = pd.DataFrame(load_data('./data_files/ms_data.xlsx')[['Age_group', 'mth_salary_tsd_group', 'positive_credit_history', 'other_credits', 'target']])
    data.rename(columns={'Age_group':'age', 'mth_salary_tsd_group':'salary', 'positive_credit_history':'credit_hist'}, inplace=True)

    st.write('## Wstp')
    st.write("""
    Niniejszy projekt prezentuje wyniki ewaluacji modelu ML do przewidywania przyznania kredytu (`target`). 
    Model zosta oceniony pod ktem dokadnoci (Accuracy) oraz obszaru pod krzyw ROC (ROC AUC).

    Wprowadzenie modeli scoringowych, takich jak regresja logistyczna, do procesu decyzyjnego przyznawania kredyt贸w ma na celu zwikszenie precyzji i obiektywnoci oceny zdolnoci kredytowej klient贸w. Zastosowanie technik scoringowych pozwala na uwzgldnienie wielu czynnik贸w wpywajcych na ryzyko kredytowe, co przekada si na lepsze zarzdzanie portfelem kredytowym instytucji finansowej.

    W ramach tego projektu wykorzystano dane zawierajce informacje o klientach, takie jak grupa wiekowa, miesiczne wynagrodzenie, historia kredytowa oraz liczba posiadanych innych kredyt贸w. Na podstawie tych danych model uczy si przewidywa, czy dany klient otrzyma kredyt (warto 1) czy te偶 nie (warto 0). 

    W kolejnych sekcjach przedstawione s szczeg贸y dotyczce danych, obliczania wag dowod贸w (WOE), wartoci informacyjnej (IV), a tak偶e wyniki ewaluacji modelu na r贸偶nych zbiorach danych. Prezentowane s r贸wnie偶 histogramy oraz macierz konfuzji, kt贸re pozwalaj na wizualn ocen rozkadu danych i skutecznoci modelu.


    ## Opis danych
    Dane u偶yte do trenowania i ewaluacji modelu zawieraj nastpujce kolumny:
    - `Age`: Grupa wiekowa
    - `salary`: Miesiczne wynagrodzenie (w tysicach)
    - `credit_hist`: Historia kredytowa (1 = pozytywna, 0 = negatywna)
    - `other_credits`: (1 = klient posiada inne kredyty, 0 = klient nie posiada innych kredyt贸w)
    - `target`: Zmienna docelowa (1 = przyznano kredyt, 0 = odm贸wiono kredytu)
    """)

    st.write("## Pr贸bka danych")
    st.write(data.head())

    st.write("### Zaadowanie danych:")
    st.code("""
    # Zaadowanie danych
    @st.cache_data
    def load_data(file):
        return pd.read_excel(file)

    data = pd.DataFrame(load_data('./data_files/ms_data.xlsx')[['Age_group', 'mth_salary_tsd_group', 'positive_credit_history', 'other_credits', 'target']])
    data.rename(columns={'Age_group':'age', 'mth_salary_tsd_group':'salary', 'positive_credit_history':'credit_hist'}, inplace=True)
    """)

    # Funkcja do obliczania WOE
    def calculate_woe(df, variable, target, smoothing=0.5):
        grouped = df.groupby(variable)[target].agg(['sum', 'count'])
        grouped.columns = ['good', 'total']
        grouped['bad'] = grouped['total'] - grouped['good']
        
        # Dodanie smoothingu do liczby dobrych i zych klient贸w, aby unikn dzielenia przez zero
        grouped['good'] = grouped['good'] + smoothing
        grouped['bad'] = grouped['bad'] + smoothing

        # Obliczanie procentu dobrych i zych klient贸w
        grouped['%good'] = grouped['good'] / grouped['total'].sum()
        grouped['%bad'] = grouped['bad'] / grouped['total'].sum()

        # Obliczanie WOE jako ln(%good / %bad)
        grouped['WOE'] = np.log(grouped['%good'] / grouped['%bad'])
        
        return pd.DataFrame(grouped['WOE'])

    # Obliczanie Distribution Good i Distribution Bad
    def calc_distribution(data, feature, target):
        lst = []
        unique_values = data[feature].unique()
        for val in unique_values:
            df = data[data[feature] == val]
            good = len(df[df[target] == 0])
            bad = len(df[df[target] == 1])
            lst.append([feature, val, good, bad])
        
        df_dist = pd.DataFrame(lst, columns=['Variable', 'Value', 'Good', 'Bad'])
        
        total_good = df_dist['Good'].sum()
        total_bad = df_dist['Bad'].sum()
        df_dist['Distribution Good'] = df_dist['Good'] / total_good
        df_dist['Distribution Bad'] = df_dist['Bad'] / total_bad
        df_dist.rename(columns={'Value':feature}, inplace=True)
        
        return df_dist[[feature, 'Good', 'Bad', 'Distribution Good', 'Distribution Bad']]

    def calc_iv(df_dist):
        df_dist['IV'] = (df_dist['Distribution Good'] - df_dist['Distribution Bad']) * df_dist['WOE']
        iv = df_dist['IV'].sum()
        return iv

    # Obliczanie WOE
    st.write('## Waga dowod贸w (WOE):')

    st.write("""
    Waga dowod贸w (Weight of Evidence, WOE) jest miar stosowan w analizie danych i modelowaniu, szczeg贸lnie w kontekcie oceny ryzyka kredytowego. WOE su偶y do przeksztacania zmiennych kategorycznych na zmienne cige, co czyni je bardziej odpowiednimi do modeli regresji logistycznej.

    WOE dla danej kategorii zmiennej jest obliczane jako logarytm naturalny stosunku odsetka pozytywnych zdarze (np. przyznanych kredyt贸w) do odsetka negatywnych zdarze (np. odm贸wionych kredyt贸w) w tej kategorii. Aby unikn problem贸w zwizanych z dzieleniem przez zero, do liczby pozytywnych i negatywnych zdarze dodawane jest tzw. smoothing. Wz贸r na WOE z uwzgldnieniem smoothingu jest nastpujcy:

    """
    + r"$\ln \left( \frac{\% \text{good + smoothing}}{\% \text{bad + smoothing}} \right)$" +
    """

    gdzie:
    - %good to procent pozytywnych zdarze w danej kategorii,
    - %bad to procent negatywnych zdarze w danej kategorii,
    - smoothing to maa staa warto dodawana w celu uniknicia dzielenia przez zero.

    WOE jest przydatne, poniewa偶:
    1. Uatwia wykrywanie zale偶noci midzy zmiennymi niezale偶nymi a zmienn zale偶n.
    2. Umo偶liwia por贸wnanie siy predykcyjnej r贸偶nych kategorii.
    3. Pomaga w identyfikacji i usuniciu zmiennych o niskiej wartoci informacyjnej.

    Wartoci WOE bliskie zeru sugeruj, 偶e dana kategoria nie ma istotnego wpywu na wynik. Wartoci dodatnie wskazuj na pozytywny wpyw, natomiast wartoci ujemne na negatywny wpyw.
    """)

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        age_woe_df = calculate_woe(data, 'age', 'target')
        st.write(age_woe_df)

    with col2:
        salary_woe_df = calculate_woe(data, 'salary', 'target')
        st.write(salary_woe_df)

    with col3:
        credit_hist_woe_df = calculate_woe(data, 'credit_hist', 'target')
        st.write(credit_hist_woe_df)

    with col4:
        other_credits_woe_df = calculate_woe(data, 'other_credits', 'target')
        st.write(other_credits_woe_df)

    st.write("### Funkcja do obliczania WOE:")
    st.code("""
    def calculate_woe(df, variable, target, smoothing=0.5):
        grouped = df.groupby(variable)[target].agg(['sum', 'count'])
        grouped.columns = ['good', 'total']
        grouped['bad'] = grouped['total'] - grouped['good']
        grouped['good'] = grouped['good'] + smoothing
        grouped['bad'] = grouped['bad'] + smoothing
        grouped['%good'] = grouped['good'] / grouped['total'].sum()
        grouped['%bad'] = grouped['bad'] / grouped['total'].sum()
        grouped['WOE'] = np.log(grouped['%good'] / grouped['%bad'])
        return pd.DataFrame(grouped['WOE'])
    """)

    # Oblicz Distribution Good i Distribution Bad dla grupowanych danych
    dist_age_df = calc_distribution(data, 'age', 'target')
    dist_salary_df = calc_distribution(data, 'salary', 'target')
    dist_credit_hist_df = calc_distribution(data, 'credit_hist', 'target')
    dist_other_credits_df = calc_distribution(data, 'other_credits', 'target')

    # Wywietl wyniki
    st.write("## Rozkad dobrych i zych kredyt贸w dla ka偶dej grupy:")

    st.write('### Wiek:')
    st.write(dist_age_df)

    st.write("""
    Analizujc rozkad dobrych i zych kredyt贸w w r贸偶nych grupach wiekowych, mo偶emy zauwa偶y kilka interesujcych trend贸w:

    - Grupa wiekowa 18-25 ma najwy偶szy udzia zar贸wno w dobrych (0.371), jak i zych kredytach (0.2987). Oznacza to, 偶e modsi klienci czciej otrzymuj kredyty, ale tak偶e czciej maj problemy z ich spat.
    - Grupa wiekowa 25-35 r贸wnie偶 ma wysoki udzia w dobrych kredytach (0.3594) i nieco ni偶szy udzia w zych kredytach (0.3054), co sugeruje, 偶e s relatywnie bardziej wiarygodni w por贸wnaniu do modszych klient贸w.
    - Starsze grupy wiekowe (45-60 i 60+) maj ni偶szy udzia w dobrych kredytach (odpowiednio 0.0812 i 0.0203), ale stosunkowo wysoki udzia w zych kredytach (odpowiednio 0.1577 i 0.0403), co mo偶e sugerowa wiksze ryzyko kredytowe wr贸d starszych klient贸w.
    """)

    st.write('### Wynagrodzenie:')
    st.write(dist_salary_df)

    st.write("""
    Przygldajc si wynagrodzeniom, mo偶emy wycign nastpujce wnioski:

    - Klienci zarabiajcy od 0 do 5 tysicy zotych miesicznie maj najwy偶szy udzia w dobrych kredytach (0.7333), co mo偶e wskazywa na ich zdolno do regularnej spaty zobowiza.
    - W miar wzrostu wynagrodzenia, udzia w dobrych kredytach maleje. Na przykad, klienci zarabiajcy od 5 do 10 tysicy zotych maj udzia 0.1217 w dobrych kredytach.
    - Najwy偶szy udzia w zych kredytach maj klienci zarabiajcy od 5 do 10 tysicy zotych (0.2416), co mo偶e sugerowa, 偶e ta grupa napotyka na trudnoci w zarzdzaniu wikszymi zobowizaniami.
    - Klienci zarabiajcy powy偶ej 20 tysicy zotych maj najni偶szy udzia w zych kredytach, co mo偶e wiadczy o ich lepszej zdolnoci kredytowej.
    """)

    st.write('### Historia kredytowa:')
    st.write(dist_credit_hist_df)

    st.write("""
    Historia kredytowa ma istotny wpyw na jako kredyt贸w:

    - Klienci z pozytywn histori kredytow maj znacznie wy偶szy udzia w dobrych kredytach (0.6812) w por贸wnaniu do tych z negatywn histori (0.3188).
    - Udzia w zych kredytach jest znacznie wy偶szy dla klient贸w z pozytywn histori kredytow (0.8523) w por贸wnaniu do tych z negatywn histori (0.1477). Mo偶e to by zaskakujce, ale sugeruje, 偶e nawet klienci z pozytywn histori mog mie trudnoci z nowymi zobowizaniami.
    """)

    st.write('### Inne kredyty:')
    st.write(dist_other_credits_df)

    st.write("""
    Posiadanie innych kredyt贸w r贸wnie偶 wpywa na ryzyko kredytowe:

    - Klienci bez innych kredyt贸w maj znacznie wy偶szy udzia w dobrych kredytach (0.7855) w por贸wnaniu do tych posiadajcych inne kredyty (0.2145).
    - Udzia w zych kredytach jest znacznie wy偶szy dla klient贸w posiadajcych inne kredyty (0.6846), co sugeruje, 偶e wielokrotne zobowizania mog zwiksza ryzyko niewypacalnoci.
    - Klienci bez innych kredyt贸w maj znacznie ni偶szy udzia w zych kredytach (0.3154), co wskazuje na ich wiksz zdolno do terminowej spaty zobowiza.
    """)

    st.write("### Obliczanie Distribution Good i Distribution Bad:")
    st.code("""
    def calc_distribution(data, feature, target):
        lst = []
        unique_values = data[feature].unique()
        for val in unique_values:
            df = data[data[feature] == val]
            good = len(df[df[target] == 0])
            bad = len(df[df[target] == 1])
            lst.append([feature, val, good, bad])
        
        df_dist = pd.DataFrame(lst, columns=['Variable', 'Value', 'Good', 'Bad'])
        
        total_good = df_dist['Good'].sum()
        total_bad = df_dist['Bad'].sum()
        df_dist['Distribution Good'] = df_dist['Good'] / total_good
        df_dist['Distribution Bad'] = df_dist['Bad'] / total_bad
        df_dist.rename(columns={'Value':feature}, inplace=True)
        
        return df_dist[[feature, 'Good', 'Bad', 'Distribution Good', 'Distribution Bad']]
            
    dist_age_df = calc_distribution(data, 'age', 'target')
    dist_salary_df = calc_distribution(data, 'salary', 'target')
    dist_credit_hist_df = calc_distribution(data, 'credit_hist', 'target')
    dist_other_credits_df = calc_distribution(data, 'other_credits', 'target')
    """)

    # Zczamyt WOE i distribution
    merged_age = pd.merge(age_woe_df, dist_age_df, on='age')
    merged_salary = pd.merge(salary_woe_df, dist_salary_df, on='salary')
    merged_credit_history = pd.merge(credit_hist_woe_df, dist_credit_hist_df, on='credit_hist')
    merged_other_credits = pd.merge(other_credits_woe_df, dist_other_credits_df, on='other_credits')

    # Obliczamy IV
    iv_age = calc_iv(merged_age)
    iv_salary = calc_iv(merged_salary)
    iv_credit_history = calc_iv(merged_credit_history)
    iv_other_credits = calc_iv(merged_other_credits)

    st.write(f'## Warto informacyjna (IV):')
    st.write(f'IV_age: {round(iv_age,4)}')
    st.write(f'IV_salary: {round(iv_salary,4)}')
    st.write(f'IV_credit_history: {round(iv_credit_history,4)}')
    st.write(f'IV_other_credits: {round(iv_other_credits,4)}')

    st.write("""
    Warto informacyjna (Information Value, IV) jest miar stosowan do oceny siy predykcyjnej zmiennej w kontekcie modelowania ryzyka kredytowego. IV pomaga w identyfikacji, kt贸re zmienne maj najwikszy wpyw na wynik modelu. Im wy偶sza warto IV, tym wiksza jest moc predykcyjna zmiennej. Wartoci IV s interpretowane wedug nastpujcych kryteri贸w:

    - IV < 0.02: Zmienna nieistotna
    - 0.02 <= IV < 0.1: Zmienna o niskiej predykcyjnoci
    - 0.1 <= IV < 0.3: Zmienna o redniej predykcyjnoci
    - IV >= 0.3: Zmienna o wysokiej predykcyjnoci

    ### Interpretacja:

    - **IV_age (-0.0926)**:
    Warto informacyjna dla wieku jest ujemna i bliska zeru, co wskazuje, 偶e wiek ma bardzo nisk moc predykcyjn. Mo偶e to sugerowa, 偶e wiek nie jest istotnym czynnikiem przy ocenie ryzyka kredytowego w tym modelu.

    - **IV_salary (-0.2233)**:
    Warto informacyjna dla wynagrodzenia jest ujemna i wynosi -0.2233, co sugeruje, 偶e wynagrodzenie ma redni moc predykcyjn. Wynagrodzenie jest istotnym czynnikiem, ale jego wpyw na wynik modelu nie jest bardzo silny.

    - **IV_credit_history (-0.169)**:
    Warto informacyjna dla historii kredytowej wynosi -0.169, co oznacza, 偶e historia kredytowa ma redni moc predykcyjn. Jest to istotny czynnik przy ocenie ryzyka kredytowego, ale nie dominuje w modelu.

    - **IV_other_credits (-0.9708)**:
    Warto informacyjna dla liczby innych kredyt贸w jest ujemna i wynosi -0.9708, co sugeruje, 偶e liczba innych kredyt贸w ma bardzo wysok moc predykcyjn. To oznacza, 偶e posiadanie innych kredyt贸w jest kluczowym czynnikiem wpywajcym na ryzyko kredytowe i powinno by brane pod uwag przy podejmowaniu decyzji kredytowych.

    Podsumowujc, analiza wartoci informacyjnych (IV) dla poszczeg贸lnych zmiennych pozwala zidentyfikowa, kt贸re czynniki maj najwikszy wpyw na przewidywanie ryzyka kredytowego. W tym przypadku, liczba innych kredyt贸w okazaa si by najwa偶niejsz zmienn, podczas gdy wiek ma najmniejszy wpyw na wynik modelu.
    """)

    st.write("### Obliczanie IV:")
    st.code("""
    def calc_iv(df_dist):
        df_dist['IV'] = (df_dist['Distribution Good'] - df_dist['Distribution Bad']) * df_dist['WOE']
        iv = df_dist['IV'].sum()
        return iv

    iv_age = calc_iv(merged_age)
    iv_salary = calc_iv(merged_salary)
    iv_credit_history = calc_iv(merged_credit_history)
    iv_other_credits = calc_iv(merged_other_credits)
    """)

    # Zmieniamy nazwy kolumn WOE, 偶eby unikn tych samych nazw po zczeniu
    merged_age.rename(columns={'WOE':'WOE_age'}, inplace=True)
    merged_salary.rename(columns={'WOE':'WOE_salary'}, inplace=True)
    merged_credit_history.rename(columns={'WOE':'WOE_credit_hist'}, inplace=True)
    merged_other_credits.rename(columns={'WOE':'WOE_other_credits'}, inplace=True)

    #Zczamy dane pocztkowe i WOE

    data = pd.merge(data, merged_age[['age','WOE_age']], on='age')
    data = pd.merge(data, merged_salary[['salary','WOE_salary']], on='salary')
    data = pd.merge(data, merged_credit_history[['credit_hist','WOE_credit_hist']], on='credit_hist')
    data = pd.merge(data, merged_other_credits[['WOE_other_credits','other_credits']], on='other_credits')

    st.write("## Dane z przypisanymi wartociami WOE:")
    st.write(data)

    # Tworzymy histogramy
    st.write("## Histogramy:")

    st.write("""
     **Histogramy rozkadu**: Te histogramy pokazuj rozkad ka偶dej cechy w zestawie danych, dajc wyobra偶enie o rozkadzie danych i mo偶liwych skonociach.
    """)

    fig, axs = plt.subplots(2, 2, figsize=(12, 10))
    axs[0, 0].hist(data['age'], bins=20, alpha=0.7, label='Wiek')
    axs[0, 0].set_title('Rozkad wieku')

    axs[0, 1].hist(data['salary'], bins=20, alpha=0.7, label='Wynagrodzenie')
    axs[0, 1].set_title('Rozkad wynagrodzenia')

    axs[1, 0].hist(data['credit_hist'], bins=20, alpha=0.7, label='Historia kredytowa')
    axs[1, 0].set_title('Rozkad historii kredytowej')
    axs[1, 0].set_xticks([0, 1])

    axs[1, 1].hist(data['other_credits'], bins=20, alpha=0.7, label='Inne kredyty')
    axs[1, 1].set_title('Rozkad innych kredyt贸w')
    axs[1, 1].set_xticks([0, 1])

    for ax in axs.flat:
        ax.set_xlabel('Warto')
        ax.set_ylabel('Czstotliwo')
        ax.legend()

    st.pyplot(fig)

    # Przygotowujemy dane pod model, podzia na macierz X i y
    X = data[['WOE_age', 'WOE_salary', 'WOE_credit_hist', 'WOE_other_credits']]
    y = data['target']

    st.write('## Przygotowanie danych pod model:')
    st.code("""
    X = data[['WOE_age', 'WOE_salary', 'WOE_credit_hist', 'WOE_other_credits']]
    y = data['target']
    """)

    # Podzia na zbiory: treningowy, walidacyjny i testowy
    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2


    st.write("## Podzia danych na zbiory testowe, trenujce i walidacyjne:")
    st.write(f"Rozmiar zestawu treningowego: {X_train.shape} - {100*round(X_train.shape[0]/X.shape[0],2)}% zbioru X.")
    st.write(f"Rozmiar zestawu walidacyjnego: {X_val.shape} - {100*round(X_val.shape[0]/X.shape[0],2)}% zbioru X.")
    st.write(f"Rozmiar zestawu testowego: {X_test.shape} - {100*round(X_test.shape[0]/X.shape[0],2)}% zbioru X.")

    st.code("""
    X = data[['WOE_age', 'WOE_salary', 'WOE_credit_hist', 'WOE_other_credits']]
    y = data['target']

    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2
    """)

    st.write("""
    ### Interpretacja:

    - **Zestaw treningowy (60%)**:
    Zestaw treningowy skada si z 385 pr贸bek, co stanowi 60% caego zbioru danych. Jest to zestaw u偶ywany do trenowania modelu, czyli do uczenia modelu na podstawie dostarczonych danych. Wikszo danych jest u偶ywana w tym celu, aby model m贸g nauczy si jak najwicej informacji z dostpnych danych.

    - **Zestaw walidacyjny (20%)**:
    Zestaw walidacyjny skada si z 129 pr贸bek, co stanowi 20% caego zbioru danych. Jest to zestaw u偶ywany do oceny modelu podczas procesu trenowania. Na podstawie wynik贸w uzyskanych na tym zbiorze, mo偶na dostroi hiperparametry modelu oraz oceni jego wydajno, zanim zostanie przetestowany na zestawie testowym. Walidacja pozwala na uniknicie przeuczenia modelu (overfitting).

    - **Zestaw testowy (20%)**:
    Zestaw testowy skada si z 129 pr贸bek, co stanowi 20% caego zbioru danych. Jest to zestaw u偶ywany do ostatecznej oceny modelu po zakoczeniu procesu trenowania i walidacji. Wyniki uzyskane na tym zbiorze odzwierciedlaj rzeczywist wydajno modelu na nieznanych wczeniej danych. Jest to kluczowy krok w procesie ewaluacji, poniewa偶 pozwala na ocen, jak dobrze model generalizuje na nowe dane.

    Podzia danych na te trzy zbiory jest istotny, poniewa偶 pozwala na rzeteln ocen wydajnoci modelu i zapewnia, 偶e model nie jest dopasowany wycznie do danych treningowych, ale potrafi tak偶e dobrze przewidywa na nowych, nieznanych danych.
    """)

    # Trenujemy model regresji logistycznej
    model = LogisticRegression()
    model.fit(X_train, y_train)

    st.write("## Trening modelu regresji logistycznej:")
    st.code("""
    model = LogisticRegression()
    model.fit(X_train, y_train)
    """)

    # Wycignicie wsp贸czynnik贸w
    coefficients = pd.DataFrame({
        'Feature': X.columns,
        'Coefficient': model.coef_[0]
    })

    # Dodanie interceptu do tabeli
    intercept = pd.DataFrame({
        'Feature': ['Intercept'],
        'Coefficient': [model.intercept_[0]]
    })

    coefficients = pd.concat([intercept, coefficients], ignore_index=True)

    # Wywietlenie tabeli wsp贸czynnik贸w
    st.write("## Wsp贸czynniki modelu regresji logistycznej")
    st.write(coefficients)

    st.write("""
    ### Interpretacja:

    - **Intercept (0.27)**:
    Intercept, czyli wyraz wolny w modelu regresji logistycznej, ma warto 0.27. Oznacza to, 偶e gdy wszystkie zmienne objaniajce (WOE_age, WOE_salary, WOE_credit_hist, WOE_other_credits) s r贸wne zero, logarytm szansy na przyznanie kredytu wynosi 0.27. W praktyce, warto interceptu przesuwa cakowity poziom log-odds w modelu.

    - **WOE_age (0.3133)**:
    Wsp贸czynnik dla WOE_age wynosi 0.3133. Warto ta sugeruje, 偶e wiek (po przeksztaceniu na WOE) ma pozytywny wpyw na log-odds przyznania kredytu. Ka偶dy wzrost WOE_age o jednostk powoduje wzrost log-odds przyznania kredytu o 0.3133, przy zao偶eniu, 偶e pozostae zmienne pozostaj bez zmian. Wiek jest wic istotnym, cho nie najsilniejszym czynnikiem w modelu.

    - **WOE_salary (0.7683)**:
    Wsp贸czynnik dla WOE_salary wynosi 0.7683. Oznacza to, 偶e miesiczne wynagrodzenie (po przeksztaceniu na WOE) ma znaczcy pozytywny wpyw na log-odds przyznania kredytu. Ka偶dy wzrost WOE_salary o jednostk powoduje wzrost log-odds przyznania kredytu o 0.7683. Wy偶sze wynagrodzenie zwiksza wic szanse na otrzymanie kredytu.

    - **WOE_credit_hist (0.4603)**:
    Wsp贸czynnik dla WOE_credit_hist wynosi 0.4603. Wskazuje to, 偶e pozytywna historia kredytowa (po przeksztaceniu na WOE) ma pozytywny wpyw na log-odds przyznania kredytu. Ka偶dy wzrost WOE_credit_hist o jednostk powoduje wzrost log-odds przyznania kredytu o 0.4603. Dobra historia kredytowa jest wic istotnym czynnikiem w modelu.

    - **WOE_other_credits (0.9185)**:
    Wsp贸czynnik dla WOE_other_credits wynosi 0.9185. Jest to najwy偶sza warto spor贸d wszystkich zmiennych, co sugeruje, 偶e liczba innych kredyt贸w (po przeksztaceniu na WOE) ma najsilniejszy pozytywny wpyw na log-odds przyznania kredytu. Ka偶dy wzrost WOE_other_credits o jednostk powoduje wzrost log-odds przyznania kredytu o 0.9185. Posiadanie innych kredyt贸w jest wic kluczowym czynnikiem zwikszajcym szanse na otrzymanie nowego kredytu.

    ### Co to s log-odds?

    Log-odds (logarytm szans) to pojcie u偶ywane w regresji logistycznej do wyra偶ania stosunku prawdopodobiestw. W kontekcie modelu regresji logistycznej, log-odds s logarytmem naturalnym stosunku prawdopodobiestwa wystpienia zdarzenia do prawdopodobiestwa jego niewystpienia.

    Matematycznie, log-odds s wyra偶one jako:
    """ + r"$\text{log-odds} = \ln\left(\frac{P}{1-P}\right)$" + """
    gdzie \( P \) jest prawdopodobiestwem wystpienia zdarzenia (np. przyznania kredytu).

    Wartoci log-odds mog by przeksztacone z powrotem na prawdopodobiestwa za pomoc funkcji logistycznej:
    """ + r"$P = \frac{e^{\text{log-odds}}}{1 + e^{\text{log-odds}}}$" + """
    
    Podsumowujc, wszystkie wsp贸czynniki w modelu s dodatnie, co oznacza, 偶e wzrost wartoci ka偶dej z tych zmiennych (po przeksztaceniu na WOE) zwiksza log-odds przyznania kredytu. W szczeg贸lnoci, liczba innych kredyt贸w ma najsilniejszy wpyw, co sugeruje, 偶e instytucje finansowe szczeg贸lnie bior pod uwag zdolno klienta do zarzdzania wieloma zobowizaniami przy ocenie ryzyka kredytowego.
            
    """)

    # Predykcja na zbiorze walidacyjnym
    y_val_pred_proba = model.predict_proba(X_val)[:, 1]
    y_val_pred = model.predict(X_val)

    # Ewaluacja modelu na zbiorze walidacyjnym
    roc_auc_val = roc_auc_score(y_val, y_val_pred_proba)
    accuracy_val = accuracy_score(y_val, y_val_pred)

    st.write("## Ewaluacja modelu na zbiorze walidacyjnym")
    st.write(f"ROC AUC: {round(roc_auc_val,4)}")
    st.write(f"Accuracy: {round(accuracy_val,4)}")

    st.write("""
    ### Interpretacja:

    - **ROC AUC (0.778)**:
    ROC AUC (Receiver Operating Characteristic Area Under the Curve) jest miar zdolnoci modelu do rozr贸偶niania midzy klasami pozytywnymi i negatywnymi. Warto 0.778 wskazuje, 偶e model ma dobr zdolno do klasyfikacji. Im bli偶ej wartoci 1, tym lepsza wydajno modelu. Wynik 0.778 sugeruje, 偶e model skutecznie odr贸偶nia klient贸w, kt贸rym nale偶y przyzna kredyt, od tych, kt贸rym kredyt nie powinien by przyznany.

    - **Accuracy (0.7442)**:
    Accuracy (dokadno) to miara okrelajca procent poprawnych przewidywa dokonanych przez model. Warto 0.7442 oznacza, 偶e model prawidowo przewiduje przyznanie lub odmow kredytu w okoo 74.42% przypadk贸w. Jest to dobry wynik, cho nale偶y pamita, 偶e accuracy mo偶e by mniej informatywne w przypadku niezr贸wnowa偶onych zbior贸w danych.


    Wyniki ewaluacji modelu na zbiorze walidacyjnym wskazuj, 偶e model regresji logistycznej osiga dobr wydajno w przewidywaniu decyzji kredytowych. Warto ROC AUC wynoszca 0.778 pokazuje, 偶e model jest skuteczny w rozr贸偶nianiu midzy klasami, a dokadno na poziomie 0.7442 sugeruje, 偶e model dobrze radzi sobie z przewidywaniem decyzji kredytowych. Te wyniki sugeruj, 偶e model mo偶e by wartociowym narzdziem wspomagajcym proces decyzyjny w przyznawaniu kredyt贸w.
    """)

    st.code("""
    y_val_pred_proba = model.predict_proba(X_val)[:, 1]
    y_val_pred = model.predict(X_val)

    roc_auc_val = roc_auc_score(y_val, y_val_pred_proba)
    accuracy_val = accuracy_score(y_val, y_val_pred)
    """)

    # Predykcja na zbiorze testowym
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = model.predict(X_test)

    # Ewaluacja modelu na zbiorze testowym
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    accuracy = accuracy_score(y_test, y_pred)

    st.write("## Ewaluacja modelu na zbiorze testowym")
    st.write(f"ROC AUC: {round(roc_auc,4)}")
    st.write(f"Accuracy: {round(accuracy,4)}")

    st.write("""
    ### Interpretacja:

    - **ROC AUC (0.8212)**:
    ROC AUC (Receiver Operating Characteristic Area Under the Curve) jest miar zdolnoci modelu do rozr贸偶niania midzy klasami pozytywnymi i negatywnymi. Warto 0.8212 wskazuje, 偶e model ma bardzo dobr zdolno do klasyfikacji. Im bli偶ej wartoci 1, tym lepsza wydajno modelu. Wynik 0.8212 sugeruje, 偶e model skutecznie odr贸偶nia klient贸w, kt贸rym nale偶y przyzna kredyt, od tych, kt贸rym kredyt nie powinien by przyznany. Lepszy wynik ROC AUC na zbiorze testowym w por贸wnaniu do zbioru walidacyjnego (0.778) wskazuje na dobr generalizacj modelu na nowych danych.

    - **Accuracy (0.7519)**:
    Accuracy (dokadno) to miara okrelajca procent poprawnych przewidywa dokonanych przez model. Warto 0.7519 oznacza, 偶e model prawidowo przewiduje przyznanie lub odmow kredytu w okoo 75.19% przypadk贸w. Jest to nieco wy偶szy wynik ni偶 na zbiorze walidacyjnym (0.7442), co sugeruje, 偶e model nie jest przeuczony i dobrze radzi sobie z nowymi danymi.


    Wyniki ewaluacji modelu na zbiorze testowym wskazuj, 偶e model regresji logistycznej osiga bardzo dobr wydajno w przewidywaniu decyzji kredytowych. Warto ROC AUC wynoszca 0.8212 pokazuje, 偶e model jest skuteczny w rozr贸偶nianiu midzy klasami, a dokadno na poziomie 0.7519 sugeruje, 偶e model dobrze radzi sobie z przewidywaniem decyzji kredytowych. Te wyniki potwierdzaj, 偶e model mo偶e by wartociowym narzdziem wspomagajcym proces decyzyjny w przyznawaniu kredyt贸w, oferujc solidne i niezawodne przewidywania.
    """)

    st.code("""
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = model.predict(X_test)

    roc_auc = roc_auc_score(y_test, y_pred_proba)
    accuracy = accuracy_score(y_test, y_pred)
    """)

    # Wyliczenie macierzy konfuzji
    conf_matrix = confusion_matrix(y_test, y_pred)

    # Wizualizacja macierzy konfuzji
    st.write("## Macierz konfuzji")
    fig, ax = plt.subplots()
    cax = ax.matshow(conf_matrix, cmap='Blues')
    plt.colorbar(cax)

    # Dodanie wartoci do kom贸rek macierzy konfuzji
    for (i, j), val in np.ndenumerate(conf_matrix):
        ax.text(j, i, f'{val}', ha='center', va='center', color='black')

    ax.set_xlabel('Przewidywane wartoci')
    ax.set_ylabel('Rzeczywiste wartoci')
    ax.set_title('Macierz konfuzji')
    ax.set_xticks(range(len(conf_matrix)))
    ax.set_yticks(range(len(conf_matrix)))

    st.pyplot(fig)

    st.write("""
    ### Interpretacja:

    Macierz konfuzji pokazuje, jak dobrze model radzi sobie z klasyfikacj danych na zbiorze testowym. Jest to narzdzie do oceny wydajnoci modelu klasyfikacyjnego, kt贸re prezentuje liczb prawdziwych i faszywych pozytyw贸w oraz negatyw贸w. Wartoci w macierzy konfuzji dla tego modelu s nastpujce:

    - **True Negatives (TN, Prawdziwe negatywy)**: 52
    - Liczba przypadk贸w, w kt贸rych model poprawnie przewidzia, 偶e kredyt nie zostanie przyznany (0).
    - **False Positives (FP, Faszywe pozytywy)**: 20
    - Liczba przypadk贸w, w kt贸rych model bdnie przewidzia, 偶e kredyt zostanie przyznany (1), podczas gdy w rzeczywistoci kredyt nie zosta przyznany (0).
    - **False Negatives (FN, Faszywe negatywy)**: 12
    - Liczba przypadk贸w, w kt贸rych model bdnie przewidzia, 偶e kredyt nie zostanie przyznany (0), podczas gdy w rzeczywistoci kredyt zosta przyznany (1).
    - **True Positives (TP, Prawdziwe pozytywy)**: 45
    - Liczba przypadk贸w, w kt贸rych model poprawnie przewidzia, 偶e kredyt zostanie przyznany (1).

    ### Metryki z macierzy konfuzji:

    Na podstawie macierzy konfuzji mo偶na obliczy kilka wa偶nych metryk:

    - **Accuracy (Dokadno)**:
    - Accuracy = (TP + TN) / (TP + TN + FP + FN)
    - Dokadno wynosi (52 + 45) / (52 + 45 + 20 + 12) = 0.7519, co oznacza, 偶e model poprawnie klasyfikuje okoo 75.19% przypadk贸w.

    - **Precision (Precyzja)**:
    - Precision = TP / (TP + FP)
    - Precyzja wynosi 45 / (45 + 20) = 0.6923, co oznacza, 偶e spor贸d wszystkich przypadk贸w przewidzianych jako pozytywne, okoo 69.23% jest rzeczywicie pozytywnych.

    - **Recall (Czuo)**:
    - Recall = TP / (TP + FN)
    - Czuo wynosi 45 / (45 + 12) = 0.7895, co oznacza, 偶e model wykrywa okoo 78.95% wszystkich rzeczywistych pozytywnych przypadk贸w.

    - **F1 Score**:
    - F1 Score = 2 * (Precision * Recall) / (Precision + Recall)
    - F1 Score wynosi 2 * (0.6923 * 0.7895) / (0.6923 + 0.7895) = 0.7386, co stanowi harmoniczn redni precyzji i czuoci.

    Macierz konfuzji pokazuje, 偶e model ma dobr zdolno do klasyfikacji, ale nadal istniej pewne bdy klasyfikacji. Wartoci True Positives i True Negatives s wysokie, co wskazuje na wysok dokadno modelu. Model ma jednak pewn liczb False Positives i False Negatives, co sugeruje, 偶e istnieje mo偶liwo dalszej optymalizacji modelu. Og贸lnie rzecz biorc, wyniki s zachcajce i sugeruj, 偶e model jest skuteczny w przewidywaniu przyznawania kredyt贸w.
    """)

    st.code("""
    conf_matrix = confusion_matrix(y_test, y_pred)
    """)

    # Rysowanie krzywej ROC dla zbioru testowego
    st.write('\n')
    st.write("## Krzywa ROC")
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    plt.figure()
    plt.plot(fpr, tpr, color='blue', lw=2, label=f'Krzywa ROC (powierzchnia = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('Wska藕nik faszywie pozytywny')
    plt.ylabel('Wska藕nik prawdziwie pozytywny')
    plt.title('Odbiorcza Krzywa Charakterystyczna')
    plt.legend(loc="lower right")

    st.pyplot(plt)

    st.write("""
    ### Krzywa ROC:

    Krzywa ROC (Receiver Operating Characteristic) przedstawia zdolno modelu do rozr贸偶niania midzy klasami pozytywnymi i negatywnymi. Na osi poziomej (X) znajduje si wska藕nik faszywie pozytywny (False Positive Rate), a na osi pionowej (Y) wska藕nik prawdziwie pozytywny (True Positive Rate). Krzywa ROC pozwala na ocen wydajnoci modelu klasyfikacyjnego przy r贸偶nych progach decyzyjnych.

    ### Interpretacja:

    - **Krzywa ROC**:
    Krzywa ROC modelu pokazuje, jak zmienia si wska藕nik prawdziwie pozytywny (TPR) w funkcji wska藕nika faszywie pozytywnego (FPR) przy r贸偶nych progach decyzyjnych. Model osiga bardzo dobr wydajno, co jest widoczne po tym, 偶e krzywa jest daleko od linii losowej (przerywana linia diagonalna).

    - **Powierzchnia pod krzyw (AUC)**:
    Warto AUC (Area Under the Curve) wynosi 0.82, co oznacza, 偶e model ma wysok zdolno do rozr贸偶niania midzy klasami. Warto AUC bliska 1 wskazuje na doskonay model, podczas gdy warto 0.5 sugeruje model losowy. Warto 0.82 wskazuje na bardzo dobr wydajno modelu w przewidywaniu przyznawania kredyt贸w.

    - **Wska藕nik prawdziwie pozytywny (TPR)**:
    TPR (True Positive Rate) to stosunek liczby prawidowo przewidzianych pozytywnych przypadk贸w do wszystkich rzeczywistych pozytywnych przypadk贸w. Jest r贸wnie偶 nazywany czuoci (sensitivity). Wy偶szy TPR wskazuje, 偶e model dobrze identyfikuje pozytywne przypadki.

    - **Wska藕nik faszywie pozytywny (FPR)**:
    FPR (False Positive Rate) to stosunek liczby bdnie przewidzianych pozytywnych przypadk贸w do wszystkich rzeczywistych negatywnych przypadk贸w. Ni偶szy FPR wskazuje, 偶e model rzadziej popenia bdy klasyfikujc negatywne przypadki jako pozytywne.

    Krzywa ROC i warto AUC dostarczaj wa偶nych informacji na temat wydajnoci modelu klasyfikacyjnego. W tym przypadku, warto AUC wynoszca 0.82 sugeruje, 偶e model regresji logistycznej ma wysok zdolno do rozr贸偶niania midzy klientami, kt贸rzy powinni otrzyma kredyt, a tymi, kt贸rzy nie powinni. Model jest skuteczny i mo偶e by z powodzeniem stosowany w procesie decyzyjnym przyznawania kredyt贸w.
    """)

    st.code("""
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    """)

    # Cross walidacja
    st.write("## Cross walidacja")
    cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='roc_auc')
    st.write(f'redni wynik ROC AUC z cross walidacji: {np.mean(cv_scores):.4f}')

    st.write("""
    ### Interpretacja:

    Cross walidacja to technika oceny wydajnoci modelu polegajca na podziale danych na wiele podzbior贸w (folds) i trenowaniu oraz testowaniu modelu na tych podzbiorach. W tym przypadku u偶yto cross walidacji z 10 podzbiorami (10-fold cross-validation), co oznacza, 偶e dane zostay podzielone na 10 r贸wnych czci. Model by trenowany na 9 czciach i testowany na pozostaej czci, a proces ten by powtarzany 10 razy, za ka偶dym razem u偶ywajc innego podzbioru jako zbioru testowego.

    redni wynik ROC AUC z cross walidacji wynosi 0.7765, co sugeruje, 偶e model ma stabiln i dobr wydajno na r贸偶nych podzbiorach danych.

    - **ROC AUC (Receiver Operating Characteristic Area Under the Curve)**:
    Warto ROC AUC mierzy zdolno modelu do rozr贸偶niania midzy klasami pozytywnymi i negatywnymi. redni wynik ROC AUC wynoszcy 0.7765 oznacza, 偶e model jest w stanie dobrze klasyfikowa przypadki na r贸偶nych podzbiorach danych. Wynik ten jest zbli偶ony do wynik贸w uzyskanych na zbiorze walidacyjnym i testowym, co wskazuje na sp贸jno i niezawodno modelu.

    redni wynik ROC AUC z cross walidacji wynoszcy 0.7765 pokazuje, 偶e model regresji logistycznej ma stabiln i dobr zdolno do rozr贸偶niania midzy klasami na r贸偶nych podzbiorach danych. Cross walidacja dostarcza bardziej wiarygodnej oceny wydajnoci modelu, poniewa偶 uwzgldnia zmienno wynik贸w na r贸偶nych czciach danych. Wysoki i sp贸jny wynik ROC AUC sugeruje, 偶e model jest dobrze dostosowany i mo偶e by z powodzeniem stosowany w praktyce do przewidywania przyznawania kredyt贸w.
    """)

    st.code("""
    cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='roc_auc')
    st.write(f'redni wynik ROC AUC z cross walidacji: {np.mean(cv_scores):.4f}')
    """)

    st.write("""
    ### Podsumowanie

    W ramach tego projektu przeprowadzono szczeg贸ow analiz i ewaluacj modelu regresji logistycznej do przewidywania przyznawania kredyt贸w. Wykorzystano dane zawierajce informacje o klientach, takie jak grupa wiekowa, miesiczne wynagrodzenie, historia kredytowa oraz liczba posiadanych innych kredyt贸w. Model zosta przeksztacony przy u偶yciu wag dowod贸w (WOE) i oceniony pod ktem r贸偶nych metryk wydajnoci.

    ### Kluczowe wnioski:

    1. **Ewaluacja modelu**:
    - Model osign wysoki wynik ROC AUC zar贸wno na zbiorze walidacyjnym (0.778), jak i testowym (0.8212), co wskazuje na jego zdolno do skutecznego rozr贸偶niania midzy klientami, kt贸rym nale偶y przyzna kredyt, a tymi, kt贸rym kredyt nie powinien by przyznany.
    - Dokadno modelu wynosia odpowiednio 74.42% na zbiorze walidacyjnym i 75.19% na zbiorze testowym, co potwierdza jego solidn wydajno.

    2. **Macierz konfuzji**:
    - Analiza macierzy konfuzji ujawnia, 偶e model ma wysok liczb prawdziwie pozytywnych i prawdziwie negatywnych klasyfikacji, ale tak偶e pewne bdy klasyfikacyjne w postaci faszywie pozytywnych i faszywie negatywnych wynik贸w.

    3. **Krzywa ROC**:
    - Krzywa ROC i warto AUC (0.82) potwierdzaj wysok wydajno modelu w zakresie rozr贸偶niania midzy klasami. Krzywa ROC jest daleko od linii losowej, co sugeruje dobr zdolno klasyfikacyjn modelu.

    4. **Cross walidacja**:
    - redni wynik ROC AUC z cross walidacji wynoszcy 0.7765 pokazuje, 偶e model ma stabiln i dobr wydajno na r贸偶nych podzbiorach danych, co potwierdza jego niezawodno.

    5. **Wartoci informacyjne (IV)**:
    - Analiza wartoci informacyjnych ujawnia, 偶e zmienne takie jak historia kredytowa i liczba innych kredyt贸w maj najwiksz moc predykcyjn. Wiek okaza si najmniej istotnym czynnikiem.

    ### Wnioski praktyczne:

    - **Zastosowanie modelu**:
    Model regresji logistycznej mo偶e by skutecznie wykorzystany w instytucjach finansowych do wspomagania procesu decyzyjnego przyznawania kredyt贸w. Dziki wysokiej zdolnoci predykcyjnej modelu, instytucje mog lepiej zarzdza ryzykiem kredytowym i podejmowa bardziej wiadome decyzje.

    - **Dalsza optymalizacja**:
    Chocia偶 model osign dobre wyniki, istnieje mo偶liwo dalszej optymalizacji, na przykad poprzez uwzgldnienie dodatkowych zmiennych lub zastosowanie bardziej zaawansowanych technik modelowania.

    Podsumowujc, model regresji logistycznej okaza si wartociowym narzdziem w przewidywaniu ryzyka kredytowego, oferujc solidne i niezawodne wyniki. Jego zastosowanie mo偶e znaczco wspom贸c procesy decyzyjne w sektorze finansowym.
    """)

with tkd:
    # Wstp
    st.header("Wstp")
    st.write("""
    W tym projekcie stworzymy model konwolucyjnej sieci neuronowej (CNN) do klasyfikacji obraz贸w rcznie pisanych cyfr z zestawu danych MNIST.
    CNN to popularna metoda deep learningowa, kt贸ra jest szczeg贸lnie skuteczna w przetwarzaniu obraz贸w.
    """)

    # Jak dziaa CNN
    st.header("Jak dziaa Konwolucyjna Sie Neuronowa (CNN)?")
    st.write("""
    Konwolucyjna Sie Neuronowa (CNN) jest typem sztucznej sieci neuronowej, kt贸ra jest szczeg贸lnie skuteczna w przetwarzaniu obraz贸w. Oto prosty opis, jak dziaa CNN:
    """)
    st.write("""
    1. **Warstwa konwolucyjna**:
    - G贸wna idea warstwy konwolucyjnej polega na przesuwaniu filtr贸w (maych macierzy) po obrazie wejciowym.
    - Ka偶dy filtr wykrywa r贸偶ne cechy obrazu, takie jak krawdzie, tekstury czy kolory.
    - Wynikiem tej operacji jest mapa cech, kt贸ra pokazuje, gdzie na obrazie wystpuj wykryte cechy.
    """)
    st.write("""
    2. **Warstwa pooling**:
    - Po warstwie konwolucyjnej nastpuje warstwa pooling (najczciej max pooling).
    - Warstwa ta zmniejsza rozmiar mapy cech, uredniajc lub wybierajc maksymalne wartoci z maych region贸w mapy.
    - Pooling pomaga w redukcji wymiar贸w danych i zwiksza odporno na przesunicia i znieksztacenia obrazu.
    """)
    st.write("""
    3. **Warstwy w peni poczone (dense)**:
    - Po kilku warstwach konwolucyjnych i pooling, mapa cech jest przeksztacana w jednowymiarowy wektor i podawana do warstw w peni poczonych.
    - Warstwy te dziaaj jak klasyczne sieci neuronowe, przetwarzajc wektor cech i uczc si klasyfikowa obraz na podstawie cech wykrytych w poprzednich warstwach.
    """)
    st.write("""
    4. **Funkcja aktywacji**:
    - Funkcje aktywacji, takie jak ReLU (Rectified Linear Unit), s stosowane po ka偶dej warstwie konwolucyjnej i dense, aby wprowadzi nieliniowo i umo偶liwi sieci uczenie si bardziej zo偶onych wzorc贸w.
    """)
    st.write("""
    5. **Funkcja straty i optymalizacja**:
    - CNN jest trenowana przy u偶yciu funkcji straty, kt贸ra mierzy r贸偶nic midzy przewidywaniami modelu a rzeczywistymi etykietami.
    - Optymalizator, taki jak Adam, aktualizuje wagi sieci, aby minimalizowa funkcj straty.
    """)
    st.write("""
    ### Podsumowanie
    Konwolucyjna Sie Neuronowa (CNN) skada si z warstw konwolucyjnych, pooling i dense, kt贸re razem ucz si wykrywa i klasyfikowa cechy obrazu. CNN s pot偶nym narzdziem do analizy obraz贸w, kt贸re znajduj szerokie zastosowanie w rozpoznawaniu obiekt贸w, detekcji i innych zadaniach zwizanych z wizj komputerow.
    """)

    # adowanie danych
    st.header("adowanie danych")
    mnist = tf.keras.datasets.mnist
    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()

    st.code("""
    mnist = tf.keras.datasets.mnist
    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()
    """, language='python')

    # Wywietlenie przykadowych obraz贸w
    st.subheader("Przykadowe obrazy")
    fig, axes = plt.subplots(1, 20, figsize=(20, 5))
    for i in range(20):
        axes[i].imshow(train_images[i], cmap='gray')
        axes[i].axis('off')
    st.pyplot(fig)

    # Przeskalowanie obraz贸w do zakresu 0-1
    train_images, test_images = train_images / 255.0, test_images / 255.0

    # Dodanie dodatkowego wymiaru (gbi kanau)
    train_images = train_images[..., tf.newaxis]
    test_images = test_images[..., tf.newaxis]

    # Definiowanie modelu
    st.header("Definiowanie modelu")
    st.write("""
    Model konwolucyjnej sieci neuronowej skada si z kilku warstw konwolucyjnych, warstw zmniejszajcych wymiary (pooling), a nastpnie warstw w peni poczonych (dense).
    Model jest kompilowany z u偶yciem optymalizatora Adam i funkcji straty sparse_categorical_crossentropy.
    """)
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dense(10, activation='softmax')
    ])

    st.code("""
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dense(10, activation='softmax')
    ])

    model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
    """, language='python')

    # Kompilacja modelu
    model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])

    # Trenowanie modelu z paskiem postpu
    st.header("Trenowanie modelu")

    st.code("""
    epochs = 5

    history = model.fit(train_images, train_labels, epochs=epochs, 
                        validation_data=(test_images, test_labels), 
                        callbacks=[StreamlitCallback()])
    """, language='python')

    epochs = 5
    progress_bar = st.progress(0)
    status_text = st.empty()

    class StreamlitCallback(tf.keras.callbacks.Callback):
        def on_epoch_end(self, epoch, logs=None):
            progress_bar.progress((epoch + 1) / epochs)
            status_text.text(f"Epoka: {epoch + 1}/{epochs}, Dokadno: {logs['accuracy']:.4f}, Walidacja dokadno: {logs['val_accuracy']:.4f}")

    history = model.fit(train_images, train_labels, epochs=epochs, 
                        validation_data=(test_images, test_labels), 
                        callbacks=[StreamlitCallback()])

    # Ewaluacja modelu
    st.header("Ewaluacja modelu")
    st.write("""
    Po zakoczeniu trenowania modelu, dokonujemy jego ewaluacji na zbiorze testowym, aby sprawdzi, jak dobrze model radzi sobie z nowymi danymi. Testujemy model na zestawie testowym i obliczamy dokadno.
    """)
    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
    st.write(f'\nTest accuracy: {test_acc}')

    st.code("""
    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
    """, language='python')

    # Wykres dokadnoci
    st.header("Wykres dokadnoci")
    st.write("""
    Poni偶szy wykres przedstawia dokadno trenowania i walidacji modelu w zale偶noci od epoki. Pozwala to zobaczy, jak model poprawia si w trakcie trenowania.
    """)
    fig, ax = plt.subplots()
    ax.plot(history.history['accuracy'], label='Dokadno trenowania')
    ax.plot(history.history['val_accuracy'], label='Dokadno walidacji')
    ax.set_xlabel('Epoka')
    ax.set_ylabel('Dokadno')
    ax.legend(loc='lower right')
    ax.set_title('Dokadno trenowania i walidacji')
    st.pyplot(fig)

    # Macierz konfuzji
    st.header("Macierz konfuzji")
    st.write("""
    Macierz konfuzji pozwala na ocen, jak dobrze model klasyfikuje poszczeg贸lne klasy. Wartoci na przektnej macierzy reprezentuj prawidowe klasyfikacje, podczas gdy wartoci poza przektn reprezentuj bdne klasyfikacje.
    """)
    predictions = model.predict(test_images)
    pred_labels = np.argmax(predictions, axis=1)
    cm = confusion_matrix(test_labels, pred_labels)

    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
    ax.set_xlabel('Predicted')
    ax.set_ylabel('True')
    ax.set_title('Macierz konfuzji')
    st.pyplot(fig)

    # Przykadowe bdnie sklasyfikowane obrazy
    st.header("Przykadowe bdnie sklasyfikowane obrazy")
    st.write("""
    Poni偶ej przedstawiamy przykady obraz贸w, kt贸re zostay bdnie sklasyfikowane przez model. Pokazuje to, jakie rodzaje bd贸w model popenia i mo偶e pom贸c w dalszym ulepszaniu modelu.
    """)
    incorrect = np.where(pred_labels != test_labels)[0]
    if len(incorrect) > 0:
        fig, axes = plt.subplots(1, 5, figsize=(10, 10))
        for i, idx in enumerate(incorrect[:5]):
            axes[i].imshow(test_images[idx].reshape(28, 28), cmap='gray')
            axes[i].set_title(f'True: {test_labels[idx]}, Pred: {pred_labels[idx]}')
            axes[i].axis('off')
        st.pyplot(fig)
    else:
        st.write("Brak bdnie sklasyfikowanych obraz贸w.")

    # Wizualizacja filtr贸w konwolucyjnych
    st.header("Wizualizacja filtr贸w konwolucyjnych")
    st.write("""
    Filtry konwolucyjne s u偶ywane w pierwszej warstwie modelu do wykrywania podstawowych cech obrazu, takich jak krawdzie. Poni偶ej przedstawiamy wizualizacj filtr贸w z pierwszej warstwy konwolucyjnej.
    """)
    first_conv_layer = model.layers[0]
    weights = first_conv_layer.get_weights()[0]

    fig, axes = plt.subplots(4, 8, figsize=(12, 6))
    for i, ax in enumerate(axes.flat):
        if i < weights.shape[-1]:
            ax.imshow(weights[:, :, 0, i], cmap='gray')
        ax.axis('off')
    st.pyplot(fig)